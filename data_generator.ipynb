{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence are a safer way to do multiprocessing. This structure guarantees that the network will only train once on each sample per epoch which is not the case with generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_size = (512,512)\n",
    "network_input_img_size = (256,400)\n",
    "network_output_imag_size = (384,432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pelonomi/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, None, 256, 400, 1) 0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_24 (ConvLSTM2D) (None, None, 256, 400, 14 7616      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, None, 256, 400, 14 56        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_25 (ConvLSTM2D) (None, None, 256, 400, 14 14168     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, None, 256, 400, 14 56        \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, None, 256, 400, 2) 254       \n",
      "_________________________________________________________________\n",
      "output (TimeDistributed)     (None, None, 256, 400, 1) 3         \n",
      "=================================================================\n",
      "Total params: 22,153\n",
      "Trainable params: 22,097\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv3D, Conv2D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, TimeDistributed\n",
    "\n",
    "input_shape = (None, 256, 400, 1)\n",
    "input = Input(input_shape, name='input')\n",
    "\n",
    "x = ConvLSTM2D(filters=14, kernel_size=(3, 3),\n",
    "                   input_shape=input_shape,\n",
    "                   padding='same', return_sequences=True)(input)\n",
    "x = BatchNormalization()(x)\n",
    "x = ConvLSTM2D(filters=14, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = TimeDistributed(Conv2D(filters=2, kernel_size=(3,3), padding='same',activation='relu'))(x)\n",
    "output = TimeDistributed(Conv2D(filters=1, kernel_size=(1,1), padding='same', activation='sigmoid'), name='output')(x)\n",
    "# output = Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "#                    activation='sigmoid',\n",
    "#                    padding='same', data_format='channels_last')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs = [input], output=[output])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.version import LooseVersion\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, seq_length = None,shuffle=True, augment=None):\n",
    "        self.seq_length = seq_length\n",
    "        self.step = 1\n",
    "        self.Xs = []\n",
    "        self.ys = []\n",
    "        self.augment = augment\n",
    "        self.frames = []\n",
    "        self.labels = []\n",
    "        #print(\"Number of elements: \\n\")\n",
    "        #print(self.nb_elements)\n",
    "    \n",
    "    def _add_frame(self, i, frame):\n",
    "        frame = self._resizer(frame,(256,400))\n",
    "        self.frames.append(frame)\n",
    "            \n",
    "    def _add_labels(self, i, cls):\n",
    "        _cls = scipy.misc.imresize(cls,(256,400))\n",
    "        #print(\"size after\" + str(_cls.shape) + \"\\n\")\n",
    "        #self.labels_tag[256] = _cls.shape[1] #this is supposed to assign a new shape but no change in shape occured\n",
    "        #self.labels_tag[257] = _cls.shape[0]\n",
    "        self.labels.append(_cls)\n",
    "\n",
    "    def _resizer(self, data, dimso):\n",
    "        data = cv2.resize(data, dimso)\n",
    "        return data\n",
    "\n",
    "\n",
    "    def load_data(self,file_name):\n",
    "         # Store sample\n",
    "        input_name, ext = os.path.splitext(file_name)\n",
    "        if ext not in ('.avi', '.mp4', '.tif'):\n",
    "            raise IOError('Format %s not supported' % (ext))\n",
    "        # Read video\n",
    "        if ext in ('.avi', '.mp4'):\n",
    "            print(\"Processing an avi file...\")\n",
    "            video = cv2.VideoCapture(file_name)\n",
    "            if LooseVersion(cv2.__version__) < LooseVersion('3'):\n",
    "                num_frames = int(video.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT))\n",
    "            else:\n",
    "                num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            print(\"Number of frames in that sample \" + str(num_frames))\n",
    "            \n",
    "            for i in range(num_frames):\n",
    "                is_valid, img = video.read()\n",
    "                if not is_valid:\n",
    "                    print('Cannot read frame: %d of %s' % (i, file_name))\n",
    "                    num_frames = i + 1\n",
    "                    break\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                self._add_frame(i, img)\n",
    "        else:  # TIFF\n",
    "            seq = Image.open(file_name)\n",
    "            num_frames = seq.n_frames\n",
    "            print(n_frames)\n",
    "            for i in range(start, seq.n_frames, step):\n",
    "                seq.seek(i)\n",
    "                a = np.array(seq.convert('L'))\n",
    "                self._add_frame(i, a)\n",
    "            #X[i,] = np.load( ID )\n",
    "\n",
    "            # Store class\n",
    "            self.label_file_fullpath = os.path.join(input_dir, label_file)\n",
    "            self.label_file = label_file\n",
    "            self.labels_tag = deepcopy(labels.tag)\n",
    "            self.nb_classes = 0\n",
    "            for i in range(start, num_frames, step):\n",
    "                labels.seek(i)\n",
    "                cls = np.array(labels)\n",
    "                self.nb_classes = max(self.nb_classes, np.max(cls) + 1)\n",
    "                # Read 'verified' tag in first frame\n",
    "                if i == 0:\n",
    "                    try:\n",
    "                        self.verified = read_verified_tag(labels.tag)\n",
    "                    except:\n",
    "                        pass\n",
    "                    # if len(self.verified) == 0:\n",
    "                    #     raise IOError('Could not read verified tag.')\n",
    "                self._add_labels(i, cls)\n",
    "            #y[i] = self.labels[ID]\n",
    "        X = self.frames\n",
    "        y = self.labels\n",
    "            \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import cv2\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=1, dim=(500,512,512,1), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        print(\"Generator Initiated\")\n",
    "\n",
    "    def __len__(self):\n",
    "        'number of iterations per epoch. value (rounded up) obtained by dividing the number of samples by the batch size'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # The batch size determines how many IDs get fed into here\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        print(\"Number of IDs \" + str(len(list_IDs_temp)))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            print(\"Id being processed \" + ID)\n",
    "            data_loader = DataLoader()\n",
    "            X_out, y_out = data_loader.load_data(ID)\n",
    "            #print(X.shape)\n",
    "            #print(y.shape)\n",
    "      \n",
    "        #X, y = self.__data_generation(list_IDs_temp)\n",
    "        #X, y = data_loader.load_data(list_IDs_temp)\n",
    "        X = np.array(X_out)\n",
    "        X = np.expand_dims(X, axis = -1)\n",
    "        y = np.array(y_out)\n",
    "        y = np.expand_dims(y, axis = -1)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "#     def __data_generation(self, list_IDs_temp):\n",
    "#         'Generates data containing batch_size samples can also do preprocessing here' # X : (n_samples, *dim, n_channels)\n",
    "#         # Initialization\n",
    "#         X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "#         y = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "\n",
    "#         # Generate data\n",
    "#         for i, ID in enumerate(list_IDs_temp):\n",
    "#             X,y_ = load_data (list_IDs_temp)\n",
    "\n",
    "#         return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Initiated\n",
      "Generator Initiated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsteps_per_epoch: Integer. Total number of steps (batches of samples) to \\nyield from generator before declaring one epoch finished and starting the \\nnext epoch. It should typically be equal to the number of samples of your \\ndataset divided by the batch size. Optional for  Sequence: if unspecified, \\nwill use the len(generator) as a number of steps.'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "# # Parameters\n",
    "params = {'dim': (500,512,512,1),\n",
    "          'batch_size': 1,\n",
    "          'n_channels': 1,\n",
    "          'n_classes': 0,\n",
    "          'shuffle': True}\n",
    "\n",
    "\n",
    "input_dir = os.path.expanduser('~/Documents/ConvLSTM/Databinary/')\n",
    "\n",
    "\n",
    "# Datasets\n",
    "partition = {}\n",
    "labels = {}\n",
    "\n",
    "partition['train'] = [input_dir + 'substack500_7fps_00.avi',input_dir + 'substack500_7fps_01.avi']\n",
    "labels['train'] = [input_dir + 'substack500_7fps_00_label.tif',input_dir + 'substack500_7fps_01_label.tif']\n",
    "partition['validation'] = [input_dir + 'substack500_7fps_02.avi']\n",
    "labels['validation'] = [input_dir + 'substack500_7fps_02_label.tif']\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)\n",
    "\n",
    "\"\"\"\n",
    "steps_per_epoch: Integer. Total number of steps (batches of samples) to \n",
    "yield from generator before declaring one epoch finished and starting the \n",
    "next epoch. It should typically be equal to the number of samples of your \n",
    "dataset divided by the batch size. Optional for  Sequence: if unspecified, \n",
    "will use the len(generator) as a number of steps.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_01.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "Epoch 1/1\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_00.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_01.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_00.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_01.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_00.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_01.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_00.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_01.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_00.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_01.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_00.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input to have 5 dimensions, but got array with shape (500, 400, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-095c51468036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     workers=1)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# When there are many workers, the do everything in parallel doing many samples at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1557\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1559\u001b[0;31m             check_batch_axis=True)\n\u001b[0m\u001b[1;32m   1560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1232\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1235\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1236\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input to have 5 dimensions, but got array with shape (500, 400, 256)"
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch = 1,\n",
    "                    validation_steps = 1,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=1)\n",
    "# When there are many workers, the do everything in parallel doing many samples at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
