{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this notebbok was supposed to contain the data generators which feed data to the network.However, I dont know what format this data is supposed to be in at the moment because I have to investigate stateful and stateless networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence are a safer way to do multiprocessing. This structure guarantees that the network will only train once on each sample per epoch which is not the case with generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_size = (512,512)\n",
    "network_input_img_size = (256,400)\n",
    "network_output_imag_size = (384,432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pelonomi/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1192: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/pelonomi/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, None, 400, 256, 1) 0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, None, 400, 256, 14 7616      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 400, 256, 14 56        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, None, 400, 256, 14 14168     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 400, 256, 14 56        \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 400, 256, 2) 254       \n",
      "_________________________________________________________________\n",
      "output (TimeDistributed)     (None, None, 400, 256, 1) 3         \n",
      "=================================================================\n",
      "Total params: 22,153\n",
      "Trainable params: 22,097\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pelonomi/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv3D, Conv2D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, TimeDistributed\n",
    "\n",
    "input_shape = (None, 400, 256, 1)\n",
    "input = Input(input_shape, name='input')\n",
    "\n",
    "x = ConvLSTM2D(filters=14, kernel_size=(3, 3),\n",
    "                   input_shape=input_shape,\n",
    "                   padding='same', \n",
    "                   return_sequences=True)(input)\n",
    "x = BatchNormalization()(x)\n",
    "x = ConvLSTM2D(filters=14, kernel_size=(3, 3),\n",
    "                   padding='same', \n",
    "                   return_sequences=True)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = TimeDistributed(Conv2D(filters=2, kernel_size=(3,3), padding='same',activation='relu'))(x)\n",
    "output = TimeDistributed(Conv2D(filters=1, kernel_size=(1,1), padding='same', activation='sigmoid'), name='output')(x)\n",
    "# output = Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "#                    activation='sigmoid',\n",
    "#                    padding='same', data_format='channels_last')(x)\n",
    "\n",
    "\n",
    "model_stateless = Model(inputs = [input], output=[output])\n",
    "model_stateless.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "model_stateless.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.version import LooseVersion\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import fnmatch\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from scipy.misc import imresize\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, seq_length = None,shuffle=True, augment=None, start=0, step = 1, frag_len = 50):\n",
    "        self.seq_length = seq_length\n",
    "        self.step = 1\n",
    "        #self.Xs = []\n",
    "        #self.ys = []\n",
    "        self.augment = augment\n",
    "        self.frames = []\n",
    "        self.labels = []\n",
    "        self.start = start\n",
    "        self.step = step\n",
    "        self.frag_len = frag_len\n",
    "        \n",
    "        #print(\"Number of elements: \\n\")\n",
    "        #print(self.nb_elements)\n",
    "    \n",
    "    def _add_frame(self, i, frame):\n",
    "        \"\"\"\n",
    "        frame : image frame to append to image sequence\n",
    "        \"\"\" \n",
    "        frame = self._resizer(frame,(256,400))\n",
    "        self.frames.append(frame)\n",
    "            \n",
    "    def _add_labels(self, i, label_img):\n",
    "        \"\"\"\n",
    "        label_img : segmentation frame to append to segmentation sequence\n",
    "        \"\"\" \n",
    "        _cls = imresize(label_img,(400,256))\n",
    "        self.labels.append(_cls)\n",
    "\n",
    "    def _resizer(self, data, dimso):\n",
    "        \"\"\"\n",
    "        data : the image to be resized \n",
    "        dimso : the dimensions to be resized to (tuple)\n",
    "        \"\"\"\n",
    "        data = cv2.resize(data, dimso)\n",
    "        return data\n",
    "    \n",
    "    def _sequence_segmenter(self,sequence, frag_len, step):\n",
    "        \"\"\"\n",
    "        sequence[list of lists]: the image sequence\n",
    "        frag_len[int]: how long each fragment length will be or number of repeated LSTM units. divisible by sequnce length\n",
    "        step[int]: steps taken between frames\n",
    "        \"\"\"\n",
    "        samples = [sequence[i:i + frag_len] for i in range(0, len(sequence), frag_len)]\n",
    "        return samples\n",
    "\n",
    "\n",
    "    def load_data(self,file_name):\n",
    "         # Store sample\n",
    "        input_dir, input_n = os.path.split(file_name)\n",
    "        input_name, ext = os.path.splitext(input_n)\n",
    "        if ext not in ('.avi', '.mp4', '.tif'):\n",
    "            raise IOError('Format %s not supported' % (ext))\n",
    "        \n",
    "        # Find matching label file\n",
    "        label_file = None\n",
    "        for f in os.listdir(input_dir):\n",
    "            if fnmatch.fnmatch(f, input_name  + '.label.tif'):\n",
    "                label_file = f\n",
    "                break\n",
    "\n",
    "        # Read multi-page label tif using PIL\n",
    "        if label_file is None:\n",
    "            print(input_name + '' + '.label.tif' + ' Not found')\n",
    "            raise IOError('Label file not found')    \n",
    "        \n",
    "    \n",
    "        # Read video in frame by frame as list of lists\n",
    "        if ext in ('.avi', '.mp4'):\n",
    "            print(\"Processing an avi file...\")\n",
    "            video = cv2.VideoCapture(file_name)\n",
    "            if LooseVersion(cv2.__version__) < LooseVersion('3'):\n",
    "                num_frames = int(video.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT))\n",
    "            else:\n",
    "                num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            print(\"Number of frames in that sample \" + str(num_frames))\n",
    "            \n",
    "            for i in range(num_frames):\n",
    "                is_valid, img = video.read()\n",
    "                if not is_valid:\n",
    "                    print('Cannot read frame: %d of %s' % (i, file_name))\n",
    "                    num_frames = i + 1\n",
    "                    break\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                self._add_frame(i, img)\n",
    "        else:  # TIFF\n",
    "            seq = Image.open(file_name)\n",
    "            num_frames = seq.n_frames\n",
    "            print(n_frames)\n",
    "            for i in range(self.start, seq.n_frames, self.step):\n",
    "                seq.seek(i)\n",
    "                a = np.array(seq.convert('L'))\n",
    "                self._add_frame(i, a)\n",
    "            \n",
    "\n",
    "        # Read matching label file frame by frame as list of lists\n",
    "        labels = Image.open(os.path.join(input_dir, label_file))\n",
    "        self.label_file_fullpath = os.path.join(input_dir, label_file)\n",
    "        self.label_file = label_file\n",
    "        self.labels_tag = deepcopy(labels.tag)\n",
    "        self.nb_classes = 0\n",
    "        for i in range(self.start, num_frames, self.step):\n",
    "            labels.seek(i)\n",
    "            cls = np.array(labels)\n",
    "            self.nb_classes = max(self.nb_classes, np.max(cls) + 1)\n",
    "            # Read 'verified' tag in first frame\n",
    "            if i == 0:\n",
    "                try:\n",
    "                    self.verified = read_verified_tag(labels.tag)\n",
    "                except:\n",
    "                    pass\n",
    "               \n",
    "            self._add_labels(i, cls)\n",
    "        \n",
    "        # fetch sequences\n",
    "        X = self.frames\n",
    "        y = np.expand_dims(self.labels[0], axis = 0)\n",
    "        y = np.expand_dims(y, axis = 0)\n",
    "        \n",
    "        \n",
    "        #now we split the sequences into sequence fragments\n",
    "        X_fragmented = self._sequence_segmenter(X, self.frag_len, self.step)\n",
    "        #y_fragmented = self._sequence_segmenter(y, self.frag_len, self.step)\n",
    "        \n",
    "        \n",
    "        X = np.array(X_fragmented)\n",
    "        y = np.array(y)\n",
    "            \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import cv2\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=1, dim=(500,512,512,1), n_channels=1,\n",
    "                 n_classes=10, shuffle=True, dummy=False):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.dummy = dummy\n",
    "        print(\"Generator Initiated\")\n",
    "\n",
    "    def __len__(self):\n",
    "        'number of iterations per epoch. value (rounded up) obtained by dividing the number of samples by the batch size'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # The batch size determines how many IDs get fed into here\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        print(\"Number of IDs \" + str(len(list_IDs_temp)))\n",
    "        \n",
    "        if self.dummy is True:\n",
    "        #do this\n",
    "            print(\"Dummy Generator Called\")\n",
    "            X = np.load('image_sequences225.npy')\n",
    "            y = np.load('labels225.npy')\n",
    "        else:\n",
    "            # Generate data\n",
    "            print(\"This Shit Real\")\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                print(\"Id being processed \" + ID)\n",
    "                data_loader = DataLoader()\n",
    "                X_out, y_out = data_loader.load_data(ID)\n",
    "\n",
    "            X = np.expand_dims(X_out, axis = -1)\n",
    "            y = np.expand_dims(y_out, axis = -1)\n",
    "\n",
    "            print(X.shape)\n",
    "            print(y.shape)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "#     def __data_generation(self, list_IDs_temp):\n",
    "#         'Generates data containing batch_size samples can also do preprocessing here' # X : (n_samples, *dim, n_channels)\n",
    "#         # Initialization\n",
    "#         X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "#         y = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "\n",
    "#         # Generate data\n",
    "#         for i, ID in enumerate(list_IDs_temp):\n",
    "#             X,y_ = load_data (list_IDs_temp)\n",
    "\n",
    "#         return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST FOR DUMMY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Initiated\n",
      "Generator Initiated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsteps_per_epoch: Integer. Total number of steps (batches of samples) to \\nyield from generator before declaring one epoch finished and starting the \\nnext epoch. It should typically be equal to the number of samples of your \\ndataset divided by the batch size. Optional for  Sequence: if unspecified, \\nwill use the len(generator) as a number of steps.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "# # Parameters\n",
    "params = {'dim': (500,256,400),\n",
    "          'batch_size': 1,\n",
    "          'n_channels': 1,\n",
    "          'n_classes': 0,\n",
    "          'shuffle': True,\n",
    "          'dummy':True}\n",
    "\n",
    "\n",
    "input_dir = os.path.expanduser('~/Documents/ConvLSTM/Databinary/')\n",
    "\n",
    "\n",
    "# Datasets\n",
    "partition = {}\n",
    "labels = {}\n",
    "\n",
    "partition['train'] = [input_dir + 'substack500_7fps_00.avi',input_dir + 'substack500_7fps_01.avi']\n",
    "labels['train'] = [input_dir + 'substack500_7fps_00_label.tif',input_dir + 'substack500_7fps_01_label.tif']\n",
    "partition['validation'] = [input_dir + 'substack500_7fps_02.avi']\n",
    "labels['validation'] = [input_dir + 'substack500_7fps_02_label.tif']\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)\n",
    "\n",
    "\"\"\"\n",
    "steps_per_epoch: Integer. Total number of steps (batches of samples) to \n",
    "yield from generator before declaring one epoch finished and starting the \n",
    "next epoch. It should typically be equal to the number of samples of your \n",
    "dataset divided by the batch size. Optional for  Sequence: if unspecified, \n",
    "will use the len(generator) as a number of steps.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e72a737c9f11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train model on dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit_generator(generator=training_generator,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0;31m#validation_data=validation_generator,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "model.fit_generator(generator=training_generator,\n",
    "                    #validation_data=validation_generator,\n",
    "                    steps_per_epoch = 1,\n",
    "                    validation_steps = 1,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=2)\n",
    "# When there are many workers, the do everything in parallel doing many samples at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST FOR NEUROFINDER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Initiated\n",
      "Generator Initiated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsteps_per_epoch: Integer. Total number of steps (batches of samples) to \\nyield from generator before declaring one epoch finished and starting the \\nnext epoch. It should typically be equal to the number of samples of your \\ndataset divided by the batch size. Optional for  Sequence: if unspecified, \\nwill use the len(generator) as a number of steps.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "# # Parameters\n",
    "params = {'dim': (500,256,400),\n",
    "          'batch_size': 1,\n",
    "          'n_channels': 1,\n",
    "          'n_classes': 0,\n",
    "          'shuffle': True,\n",
    "          'dummy':False}\n",
    "\n",
    "\n",
    "input_dir = os.path.expanduser('~/Documents/ConvLSTM/Databinary/')\n",
    "\n",
    "\n",
    "# Datasets\n",
    "partition = {}\n",
    "labels = {}\n",
    "\n",
    "partition['train'] = [input_dir + 'substack500_7fps_00.avi',input_dir + 'substack500_7fps_01.avi']\n",
    "labels['train'] = [input_dir + 'substack500_7fps_00_label.tif',input_dir + 'substack500_7fps_01_label.tif']\n",
    "partition['validation'] = [input_dir + 'substack500_7fps_02.avi']\n",
    "labels['validation'] = [input_dir + 'substack500_7fps_02_label.tif']\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)\n",
    "\n",
    "\"\"\"\n",
    "steps_per_epoch: Integer. Total number of steps (batches of samples) to \n",
    "yield from generator before declaring one epoch finished and starting the \n",
    "next epoch. It should typically be equal to the number of samples of your \n",
    "dataset divided by the batch size. Optional for  Sequence: if unspecified, \n",
    "will use the len(generator) as a number of steps.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IDs 1\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_00.avi\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_01.avi\n",
      "Processing an avi file...\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "Number of frames in that sample 500\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pelonomi/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/home/pelonomi/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n",
      "/home/pelonomi/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/home/pelonomi/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50, 400, 256)\n",
      "(1, 1, 400, 256)\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_01.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "(10, 50, 400, 256)\n",
      "(1, 1, 400, 256)\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_00.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "(10, 50, 400, 256)\n",
      "(1, 1, 400, 256)\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_01.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "(10, 50, 400, 256)\n",
      "(1, 1, 400, 256)\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_00.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "(10, 50, 400, 256)\n",
      "(1, 1, 400, 256)\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_01.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "(10, 50, 400, 256)\n",
      "(1, 1, 400, 256)\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_00.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "(10, 50, 400, 256)\n",
      "(1, 1, 400, 256)\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_01.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "(10, 50, 400, 256)\n",
      "(1, 1, 400, 256)\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_00.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "(10, 50, 400, 256)\n",
      "(1, 1, 400, 256)\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_01.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "(10, 50, 400, 256)\n",
      "(1, 1, 400, 256)\n",
      "Number of IDs 1\n",
      "Id being processed /home/pelonomi/Documents/ConvLSTM/Databinary/substack500_7fps_00.avi\n",
      "Processing an avi file...\n",
      "Number of frames in that sample 500\n",
      "(10, 50, 400, 256)\n",
      "(1, 1, 400, 256)\n",
      "(10, 50, 400, 256)\n",
      "(1, 1, 400, 256)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input to have 5 dimensions, but got array with shape (10, 50, 400, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e72a737c9f11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     workers=2)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# When there are many workers, the do everything in parallel doing many samples at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1557\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1559\u001b[0;31m             check_batch_axis=True)\n\u001b[0m\u001b[1;32m   1560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1232\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1235\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1236\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflowenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input to have 5 dimensions, but got array with shape (10, 50, 400, 256)"
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "model.fit_generator(generator=training_generator,\n",
    "                    #validation_data=validation_generator,\n",
    "                    steps_per_epoch = 1,\n",
    "                    validation_steps = 1,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=2)\n",
    "# When there are many workers, the do everything in parallel doing many samples at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
